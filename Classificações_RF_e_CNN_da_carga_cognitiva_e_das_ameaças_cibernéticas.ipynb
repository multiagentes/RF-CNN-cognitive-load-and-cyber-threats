{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pRMnWK6Gw_3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar o PyTorch, primeiro devemos instalá-lo:"
      ],
      "metadata": {
        "id": "Woq0dF0PH1yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Instalação do PyTorch\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# Importando o PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "FsOlY2Q2IQTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O PyTorch fornece tensors que são estruturas de dados multidimensionais similares aos arrays do NumPy, além de operações diferenciáveis para construção de redes neurais.\n",
        "\n",
        "Para carregar os dados, podemos utilizar as mesmas bibliotecas como Pandas e NumPy:"
      ],
      "metadata": {
        "id": "rwlRiG0IITLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Lendo dados de treino e teste\n",
        "X_treino = pd.read_csv(\"treino.csv\")\n",
        "X_teste = pd.read_csv(\"teste.csv\")\n",
        "\n",
        "# Convertendo para Tensors\n",
        "X_treino = torch.from_numpy(X_treino.values)\n",
        "X_teste = torch.from_numpy(X_teste.values)\n"
      ],
      "metadata": {
        "id": "_XH_hqnCIaqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O pré-processamento também segue um fluxo similar, porém agora utilizando a biblioteca torch ao invés de sklearn:"
      ],
      "metadata": {
        "id": "26pcamvwIe1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Normalizando os dados\n",
        "transforms = torch.nn.Sequential(\n",
        "    torch.nn.Linear(num_features, num_features),\n",
        "    torch.nn.BatchNorm1d(num_features),\n",
        "    torch.nn.ReLU(),\n",
        ")\n",
        "\n",
        "X_treino = transforms(X_treino)\n",
        "X_teste = transforms(X_teste)\n"
      ],
      "metadata": {
        "id": "WR-63d2sIlUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Para definir e treinar a rede neural, utilizamos as classes nn.Module e nn.Sequential do PyTorch:"
      ],
      "metadata": {
        "id": "keXwOp0pIpLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Definindo a CNN\n",
        "modelo = nn.Sequential(\n",
        "    nn.Conv2d(...),\n",
        "    nn.MaxPool2d(...),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(...)\n",
        ")\n",
        "\n",
        "# Definindo a função de loss e otimizador\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "otimizador = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
        "\n",
        "# Treinando a rede\n",
        "for epoca in range(10):\n",
        "    y_pred = modelo(X_treino)\n",
        "    loss = criterio(y_pred, y_treino)\n",
        "    loss.backward()\n",
        "    otimizador.step()\n",
        "    otimizador.zero_grad()\n",
        "\n",
        "# Avaliando no conjunto de teste\n",
        "with torch.no_grad():\n",
        "    y_test_pred = modelo(X_teste)\n",
        "    acc = (y_test_pred.argmax(dim=1) == y_teste).float().mean()\n"
      ],
      "metadata": {
        "id": "0oLb0OooIuux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se nota, utilizamos o PyTorch para treinar redes neurais convolucionais.\n",
        "\n",
        "Além da instalação e importação das bibliotecas, definimos o device CPU, no qual o modelo e os dados serão alocados:"
      ],
      "metadata": {
        "id": "YWFMa4BiIx4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Definindo o device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "# Modelo para o device\n",
        "modelo = modelo.to(device)\n",
        "\n",
        "# Dados para o device\n",
        "X_treino = X_treino.to(device)\n",
        "y_treino = y_treino.to(device)\n",
        "X_teste = X_teste.to(device)\n",
        "y_teste = y_teste.to(device)\n"
      ],
      "metadata": {
        "id": "n-iJfqSZJeRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outra técnica importante é o uso de DataLoaders e DataSets para carregar os dados em batches:"
      ],
      "metadata": {
        "id": "A1O9ML0-KBOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Imports\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset\n",
        "class MeuDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(MeuDataset(X_treino, y_treino), batch_size=32)\n",
        "test_loader = DataLoader(MeuDataset(X_teste, y_teste), batch_size=32)\n"
      ],
      "metadata": {
        "id": "zjBz2Tk6KMUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sendo assim, o treinamento fica:"
      ],
      "metadata": {
        "id": "ar8mXliQKZ0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "for epoca in range(10):\n",
        "\n",
        "  for batch in train_loader:\n",
        "\n",
        "    X, y = batch\n",
        "\n",
        "    # Treinamento\n",
        "\n",
        "    loss.backward()\n",
        "    otimizador.step()\n",
        "    otimizador.zero_grad()\n",
        "\n",
        "  # Validação no conjunto de teste\n",
        "\n",
        "\n",
        "\n",
        "E a inferência:\n",
        "\n",
        "python\n",
        "\n",
        "for batch in test_loader:\n",
        "\n",
        "  X, y = batch\n",
        "\n",
        "  # Inferência\n",
        "\n",
        "  y_pred = modelo(X)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxwpdMPbKbCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para monitorar e salvar os checkpoints do modelo durante o treinamento, podemos utilizar o PyTorch Lightning:"
      ],
      "metadata": {
        "id": "AYqjg5OMKge9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Imports\n",
        "from pytorch_lightning import LightningModule\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# Classe LightningModule\n",
        "class LitModel(LightningModule):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.modelo = nn.Sequential(...)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.modelo(x)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    # Lógica de treinamento\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    # Lógica de teste/validação\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return optimizer\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = LitModel()\n",
        "\n",
        "# Callback de checkpoint\n",
        "checkpoint_callback = ModelCheckpoint()\n",
        "\n",
        "# Treinador\n",
        "treinador = pl.Trainer(callbacks=[checkpoint_callback])\n",
        "\n",
        "# Treinando\n",
        "treinador.fit(modelo, train_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "d4vcEwydKiT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "O PyTorch Lightning abstrai e automatiza vários aspectos do treinamento, como cálculo do número de épocas, avaliação no conjunto de teste e callbacks.\n",
        "\n",
        "Também podemos utilizar o Weights & Biases (W&B) para monitoramento em tempo real:"
      ],
      "metadata": {
        "id": "66F_S4szKoa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Imports\n",
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "wandb.init(project=\"meu_projeto\")\n",
        "\n",
        "treinador = Trainer(logger=WandbLogger())\n",
        "\n",
        "# Durante treinamento\n",
        "wandb.log({\"loss\": loss, \"accuracy\": acc})\n"
      ],
      "metadata": {
        "id": "EXE7ZN3-Ktdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O W&B integra com o Lightning para gerar dashboards com gráficos, permitindo acompanhar métricas como loss, accuracy, learning rate ao longo do treinamento.\n",
        "\n",
        "Para deploy do modelo treinado, podemos utilizar o ONNX:"
      ],
      "metadata": {
        "id": "nvy9hYxuK0_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Exportando para .onnx\n",
        "torch.onnx.export(modelo, dummy_input, \"modelo.onnx\")\n",
        "\n",
        "# Inferência com ONNX Runtime\n",
        "import onnxruntime as rt\n",
        "sess = rt.InferenceSession(\"modelo.onnx\")\n",
        "\n",
        "entrada = ... # dados de entrada\n",
        "saida = sess.run(None, {sess.get_inputs()[0].name: entrada})\n"
      ],
      "metadata": {
        "id": "PCG9N0mwK4Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularização - Evita overfitting:"
      ],
      "metadata": {
        "id": "co_B3JcrK7fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Dropout\n",
        "nn.Dropout(p=0.5)\n",
        "\n",
        "# BatchNorm\n",
        "nn.BatchNorm1d(num_features)\n",
        "\n",
        "# Weight Decay\n",
        "# Penaliza pesos elevados\n",
        "optimizer = optim.Adam(modelo.parameters(), weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "hmXR1yt4K8NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentação de dados - Aumenta a variabilidade do conjunto de treinamento:"
      ],
      "metadata": {
        "id": "X1iJTWB7LbMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Imports\n",
        "from torchvision import transforms\n",
        "\n",
        "# Transformações aleatórias nos dados\n",
        "transforms = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.RandomRotation(degrees=15),\n",
        "  transforms.ColorJitter(hue=0.1),\n",
        "])\n",
        "\n",
        "dataset = MeuDataset(X, y, transforms)"
      ],
      "metadata": {
        "id": "eaFhB4thLgpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h2sV6X2dLhVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning - Encontra a melhor configuração:"
      ],
      "metadata": {
        "id": "xvpv5zh7LjIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Imports\n",
        "from ray import tune\n",
        "\n",
        "# Função para treinar modelo\n",
        "def treinar_modelo(config):\n",
        "\n",
        "  modelo = Net(config)\n",
        "  modelo.fit(...)\n",
        "  acc = modelo.score(...)\n",
        "\n",
        "  return acc\n",
        "\n",
        "# Procura exaustiva de hyperparameters\n",
        "best_config = tune.run(\n",
        "  treinar_modelo,\n",
        "  config={\n",
        "    \"lr\": tune.grid_search([0.01, 0.001, 0.0001]),\n",
        "    \"momentum\": tune.grid_search([0.9, 0.99]),\n",
        "    \"batch_size\": 32\n",
        "  }\n",
        ")\n",
        "\n",
        "print(best_config)"
      ],
      "metadata": {
        "id": "1aqqfNO_LkW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning - Usa pesos pré-treinados:"
      ],
      "metadata": {
        "id": "z3JRFO5DLpD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Carregando modelo pré-treinado\n",
        "modelo = models.resnet18(pretrained=True)\n",
        "\n",
        "# Congelando parâmetros já treinados\n",
        "for param in modelo.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Adicionando camadas novas para fine-tuning\n",
        "modelo.fc = nn.Linear(512, num_classes)"
      ],
      "metadata": {
        "id": "8f9ghxmDLsFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Models - Combina vários modelos:"
      ],
      "metadata": {
        "id": "EH31yoKFL0WD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Criando dois modelos\n",
        "modeloA = Net()\n",
        "modeloB = Net()\n",
        "\n",
        "# Treinando\n",
        "modeloA.fit(...)\n",
        "modeloB.fit(...)\n",
        "\n",
        "# Predições em conjunto\n",
        "def ensemble_predict(x):\n",
        "  return modeloA(x) + modeloB(x) / 2"
      ],
      "metadata": {
        "id": "wDXRn0EsL24S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para servir o modelo treinado via API REST usando Django:"
      ],
      "metadata": {
        "id": "wnI51xLkL5st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "from django.conf.urls import url\n",
        "from django.http import JsonResponse\n",
        "from django.apps import AppConfig\n",
        "\n",
        "class PredicaoConfig(AppConfig):\n",
        "    name = 'predicao'\n",
        "\n",
        "    def ready(self):\n",
        "        # Carrega modelo\n",
        "        global modelo\n",
        "        modelo = Net()\n",
        "        modelo.load_state_dict(torch.load('pesos.pth'))\n",
        "\n",
        "# Rota para requisição POST\n",
        "def model_predict(request):\n",
        "\n",
        "    # Lê dados do corpo da requisição\n",
        "    dados = json.loads(request.body)\n",
        "\n",
        "    # Pré-processa dados\n",
        "    dados = normalizar(dados)\n",
        "\n",
        "    # Converte para tensor\n",
        "    dados = torch.from_numpy(dados)\n",
        "\n",
        "    # Prediz\n",
        "    saida = modelo(dados)\n",
        "\n",
        "    # Converte resposta para JSON\n",
        "    resposta = saida.tolist()\n",
        "\n",
        "    return JsonResponse(resposta, safe=False)\n",
        "\n",
        "# URLs mapeadas para a view\n",
        "urlpatterns = [\n",
        "    url(r'^predict/$', model_predict)\n",
        "]"
      ],
      "metadata": {
        "id": "li28FsSxL8-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E no arquivo urls.py principal do projeto Django:"
      ],
      "metadata": {
        "id": "K84DV-NkMBgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "from django.urls import path, include\n",
        "\n",
        "urlpatterns = [\n",
        "    # Outras rotas\n",
        "    path('api/', include('predicao.urls'))\n",
        "]"
      ],
      "metadata": {
        "id": "u6WmwXOsMEmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dessa forma integramos o modelo PyTorch em produção via API REST usando o framework Django.\n",
        "\n",
        "O pré-processamento dos sinais fNIRS pode envolver técnicas como filtragem, normalização e extração de features:"
      ],
      "metadata": {
        "id": "Zn_bjOKYMKNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "# Filtragem\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "def filter_signal(signal):\n",
        "  b, a = butter(order, cutoff, btype='lowpass')\n",
        "  return filtfilt(b, a, signal)\n",
        "\n",
        "# Normalização\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "signal = scaler.fit_transform(signal)\n",
        "\n",
        "# Extração de features\n",
        "from tsfresh import extract_features\n",
        "\n",
        "X = extract_features(signal, column_id='id')"
      ],
      "metadata": {
        "id": "ZnAklwK-MOCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o classificador Random Forest:"
      ],
      "metadata": {
        "id": "OdLOKpdqMP0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Treinamento\n",
        "rf.fit(X_treino, y_treino)\n",
        "\n",
        "# Predição\n",
        "y_pred = rf.predict(X_teste)\n",
        "\n",
        "# Avaliação\n",
        "rf_accuracy = accuracy_score(y_teste, y_pred)"
      ],
      "metadata": {
        "id": "cwO7jTGjMSeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E para a CNN:"
      ],
      "metadata": {
        "id": "zzxyBkuhMUaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(n_timesteps,1)))\n",
        "cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Treinamento\n",
        "cnn.fit(X_treino, y_treino, epochs=10)\n",
        "\n",
        "# Predição\n",
        "y_pred = cnn.predict(X_teste)\n",
        "\n",
        "# Avaliação\n",
        "cnn_accuracy = accuracy_score(y_teste, y_pred>0.5)"
      ],
      "metadata": {
        "id": "8G5jcneiMW3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comparar as métricas:"
      ],
      "metadata": {
        "id": "W_Bml5gPMZGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy*100:.2f}%\")\n",
        "print(f\"CNN Accuracy: {cnn_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "Z-5oj0qlMbXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2V35Ms-QLteK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R0QhILNwJfdw"
      }
    }
  ]
}